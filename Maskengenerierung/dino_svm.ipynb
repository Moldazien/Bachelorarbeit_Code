{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dino_svm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**notebook um mit attentionmaps von dino und svm mit lineraem und rvf kernel masken zu berechnen und evaluierung dieser**"
      ],
      "metadata": {
        "id": "KISPrUpkFDne"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgL915d4uAab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HUz2IqPtfLz"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi\n",
        "\n",
        "!cd /content/cocoapi/PythonAPI && make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbTFt2YihL9B"
      },
      "source": [
        " !pip install timm\n",
        " \n",
        " !git clone https://github.com/Moldazien/BA.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyfQxEwgMg8R"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/BA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4No_m7wkJtI2"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import cv2\n",
        "import random\n",
        "import colorsys\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import skimage.io\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms as pth_transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import utils\n",
        "import vision_transformer as vits\n",
        "\n",
        "from pycocotools.coco import COCO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arch = 'vit_base'\n",
        "patch_size = 8\n",
        "\n",
        "output_dir = 'OUTPUT_DIR'\n",
        "    \n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "qrBZR_kaqpgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def crop_fkt(bbox, area, percentile, width, height):\n",
        "  width = width\n",
        "  height = height\n",
        "\n",
        "  width_edge = bbox[2]*percentile\n",
        "  height_edge = bbox[3]*percentile\n",
        "\n",
        "  edge = (width_edge + height_edge)\n",
        "\n",
        "  tx = max(bbox[0]-edge, 0)\n",
        "  ty = max(bbox[1]-edge, 0)\n",
        "  bx = min(bbox[0]+bbox[2]+edge, width)\n",
        "  by = min(bbox[1]+bbox[3]+edge, height)\n",
        "\n",
        "  area = 80000\n",
        "  wid = bx - tx\n",
        "  hei = by - ty\n",
        "\n",
        "  p = np.sqrt(area/(wid*hei))\n",
        "\n",
        "  imagewidth = int((int(wid*p))/10)\n",
        "  imageheight = int((int(hei*p))/10)\n",
        "\n",
        "  img_size = (imageheight, imagewidth)\n",
        "\n",
        "  return (tx, ty, bx, by), img_size"
      ],
      "metadata": {
        "id": "19kz1U-IETX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gt_tensors(attentions, maskimg, bbox, width, height):\n",
        "  percentile = 0 #percentile hier 0, da attentionmaps schon zugeschnitten sind\n",
        "  patch_size = 8\n",
        "  image_size = (480, 480)\n",
        "  area = 60000\n",
        "\n",
        "  box, img_size = crop_fkt(bbox, area, percentile, width, height)\n",
        "\n",
        "  img_size = (16, 16)\n",
        "\n",
        "  crop_mask = maskimg.crop(box=box)\n",
        "\n",
        "  mask = np.asarray(crop_mask)\n",
        "  mask = torch.tensor(mask)\n",
        "  mask = mask.reshape(1, mask.shape[0], mask.shape[1]).float()\n",
        "\n",
        "  masktransforms = pth_transforms.Compose([\n",
        "                                      pth_transforms.Resize(img_size, interpolation = InterpolationMode('nearest')),\n",
        "                                     ])\n",
        "  \n",
        "  atttransforms = pth_transforms.Compose([\n",
        "                                      pth_transforms.Resize(img_size),\n",
        "                                     ])\n",
        "\n",
        "  attentions = atttransforms(attentions)\n",
        "  mask = masktransforms(mask)\n",
        "\n",
        "  return attentions, mask"
      ],
      "metadata": {
        "id": "TbXgM6gfESCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "class NACTI_seg(Dataset):\n",
        "  def __init__(self, annotations_file, dataset_dir):\n",
        "    self.annotations_file = annotations_file\n",
        "    self.coco = COCO(annotations_file) \n",
        "\n",
        "    self.dataset = dataset_dir\n",
        "    self.img_ids = self.coco.getImgIds()\n",
        "    self.ann_ids = self.coco.getAnnIds()\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ann_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    ann_id = self.ann_ids[idx]\n",
        "    ann = self.coco.loadAnns([ann_id])\n",
        "    img_id = ann[0]['image_id']\n",
        "    img = self.coco.loadImgs([img_id])\n",
        "\n",
        "    img_path = self.dataset + '/images/' + img[0]['file_name']\n",
        "    image = None\n",
        "    mask = None\n",
        "    bbox = None#\n",
        "\n",
        "    width = img[0]['width']\n",
        "    height = img[0]['height']\n",
        "\n",
        "    attentions_path = self.dataset + '/tensors/' + str(ann_id) + '_attention.pt'\n",
        "    attentions = torch.load(attentions_path, map_location = device)\n",
        "    \n",
        "    mask = self.coco.annToMask(ann[0]) #mask for instance segmentation\n",
        "    bbox = ann[0]['bbox']\n",
        "\n",
        "    maskImg = Image.fromarray(mask)\n",
        "\n",
        "    attentions, mask = gt_tensors(attentions, maskImg, bbox, width, height)\n",
        "\n",
        "    attentions = attentions.to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    return attentions, mask, ann[0]"
      ],
      "metadata": {
        "id": "ff0rHvnjEJSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = NACTI_seg('TRAINSET__ANNOTATION_JSON', 'DATASET_PATH')"
      ],
      "metadata": {
        "id": "ukwpo5ddpkoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids = np.arange(0,trainset.__len__(),1)\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for id in train_ids:\n",
        "  x, y, ann = trainset.__getitem__(id)\n",
        "\n",
        "  mask_shape = y.shape\n",
        "\n",
        "  Xarray = np.asarray(x)\n",
        "  Yarray = np.asarray(y.reshape(mask_shape[1], mask_shape[2]))\n",
        "\n",
        "  X.append(Xarray.transpose(1,2,0))\n",
        "  Y.append(Yarray)  \n",
        "\n",
        "  output_dir = '/content'\n",
        "\n",
        "  os.makedirs(output_dir, exist_ok=True)                              # |||| maybe try no normalize"
      ],
      "metadata": {
        "id": "ZjhsMSGmtX6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsvqKTQK3EIs"
      },
      "source": [
        "X_arr = np.asarray(X)\n",
        "Y_arr = np.asarray(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_HSqVQ54bAT"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "n_attention_maps = X_arr.shape[3]\n",
        "\n",
        "clf = svm.SVC(cache_size = 20000, max_iter = 1000000) #trainingsparameter für rbf svm\n",
        "#clf = svm.LinearSVC()  #training für lin svm\n",
        "X_svm = X_arr.reshape(-1, n_attention_maps)\n",
        "Y_svm = Y_arr.reshape(-1) * 1\n",
        "clf.fit(X_svm, Y_svm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uWz4nMl3rTq"
      },
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "dump(clf, 'FILE.joblib') #speichern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9yAb-t2fjyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73888fde-27c8-4023-8833-46b9ced1bde2"
      },
      "source": [
        "drive.flush_and_unmount()\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing"
      ],
      "metadata": {
        "id": "WJMwdkJ-9KDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json, yaml\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "from pycocotools import mask as cocomask\n",
        "from pycocotools import coco as cocoapi\n",
        "\n",
        "#binäre masken umwandeln um in json speichern zu können\n",
        "def __get_annotation__(mask, image=None):\n",
        "\n",
        "  labelMask = np.expand_dims(mask, axis=2)\n",
        "  labelMask = labelMask.astype('uint8')\n",
        "  labelMask = np.asfortranarray(labelMask)\n",
        "  Rs = cocomask.encode(labelMask)\n",
        "  assert len(Rs) == 1\n",
        "  Rs = Rs[0]\n",
        "\n",
        "  area = cocomask.area(Rs)\n",
        "\n",
        "  return Rs, area#, [x, y, w, h] "
      ],
      "metadata": {
        "id": "Yf9pV86X9VxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "class TestSet(Dataset):\n",
        "  def __init__(self, annotations_file, dataset_dir):\n",
        "    self.annotations_file = annotations_file\n",
        "    self.coco = COCO(annotations_file)  #for fast reading\n",
        "    \n",
        "    #self.transform = transform\n",
        "    #self.target_transform = target_transforms\n",
        "\n",
        "    self.dataset = dataset_dir\n",
        "    self.img_ids = self.coco.getImgIds()\n",
        "    self.ann_ids = self.coco.getAnnIds()\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ann_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    ann_id = self.ann_ids[idx]\n",
        "    ann = self.coco.loadAnns([ann_id])\n",
        "    img_id = ann[0]['image_id']\n",
        "    img = self.coco.loadImgs([img_id])\n",
        "\n",
        "    img_path = self.dataset + '/images/' + img[0]['file_name']\n",
        "    image = None\n",
        "    mask = None\n",
        "    bbox = None#\n",
        "    \n",
        "    width = img[0]['width']\n",
        "    height = img[0]['height']\n",
        "\n",
        "    attentions_path = self.dataset + '/tensors/' + str(ann_id) + '_attention.pt'\n",
        "    attentions = torch.load(attentions_path, map_location = device)\n",
        "    \n",
        "    mask = self.coco.annToMask(ann[0])\n",
        "    #mask = np.zeros((3000,3000))\n",
        "    bbox = ann[0]['bbox']\n",
        "\n",
        "    maskImg = Image.fromarray(mask)\n",
        "\n",
        "    attentions = attentions.to(device)\n",
        "\n",
        "    return attentions, mask, ann[0], bbox, (height, width)"
      ],
      "metadata": {
        "id": "7hTwysto9oHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "testset = TestSet('ANNOTATION_JSON', 'DATASET_PATH')"
      ],
      "metadata": {
        "id": "H-g98tkz94Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "clf = load('MODEL_FILE_joblib') "
      ],
      "metadata": {
        "id": "i3uFsnbg99MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inferenz mit rbfSVM\n",
        "\n",
        "test_ids = np.arange(0,testset.__len__(),1)\n",
        "\n",
        "Ygt = []\n",
        "Ypred = []\n",
        "\n",
        "Ygt = []\n",
        "Ypred = []\n",
        "\n",
        "#smal_pred = []\n",
        "\n",
        "pred_anns = []\n",
        "\n",
        "for i in test_ids:\n",
        "\n",
        "  attentions, gtmask, annotation, bbox, dimensions = testset.__getitem__(i)\n",
        "\n",
        "  Ygt.append(gtmask)\n",
        "  \n",
        "  area = 6400\n",
        "  wid = bbox[3]\n",
        "  hei = bbox[2]\n",
        "\n",
        "  p = np.sqrt(area/(wid*hei))\n",
        "  pre_dim = (int(bbox[3]*p), int(bbox[2]*p))\n",
        "\n",
        "\n",
        "  transforms = pth_transforms.Compose([ \n",
        "                                        pth_transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
        "                                        pth_transforms.Resize(pre_dim),\n",
        "                                        pth_transforms.GaussianBlur(kernel_size=11, sigma=4),#pth_transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
        "                                      ])\n",
        "  attentions = transforms(attentions)\n",
        "\n",
        "  attentions = np.asarray(attentions).transpose(1,2,0)\n",
        "  org_size = (attentions.shape[0], attentions.shape[1])\n",
        "\n",
        "  attentions = attentions.reshape(-1, 12)\n",
        "\n",
        "  mask_part = clf.predict(attentions)\n",
        "  mask_part = mask_part.reshape(org_size)\n",
        "\n",
        "  mask = Image.fromarray(mask_part)\n",
        "  \n",
        "  transforms = pth_transforms.Compose([ \n",
        "                                        pth_transforms.Resize((int(bbox[3]), int(bbox[2])), interpolation = InterpolationMode('nearest')),\n",
        "                                      ])\n",
        "  mask = transforms(mask)\n",
        "\n",
        "  mask_part = np.asarray(mask)\n",
        "  pred_mask = np.zeros((dimensions))\n",
        "\n",
        "\n",
        "  for i in range(mask_part.shape[0]):\n",
        "    for j in range(mask_part.shape[1]):\n",
        "      pred_mask[int(bbox[1]) + i, int(bbox[0]) + j] = mask_part[i, j]\n",
        "\n",
        "\n",
        "  seg, area = __get_annotation__(pred_mask)\n",
        "\n",
        "  annotation['pred_seg'] = seg\n",
        "  annotation['pred_seg']['counts'] = annotation['pred_seg']['counts'].decode()\n",
        "  annotation['pred_area'] = int(area)\n",
        "\n",
        "  pred_anns.append(annotation)\n",
        "\n",
        "  Ypred.append(pred_mask)\n"
      ],
      "metadata": {
        "id": "nC1Kk_Zyotm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inferenz mit linSVM\n",
        "\n",
        "test_ids = np.arange(0,testset.__len__(),1)\n",
        "\n",
        "Ygt = []\n",
        "Ypred = []\n",
        "\n",
        "\n",
        "pred_anns = []\n",
        "\n",
        "for i in test_ids:\n",
        "  attentions, gtmask, annotation, bbox, dimensions = testset.__getitem__(i)\n",
        "\n",
        "  Ygt.append(gtmask)\n",
        "\n",
        "  transforms = pth_transforms.Compose([ \n",
        "                                        pth_transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
        "                                        pth_transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
        "                                        pth_transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
        "                                        pth_transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
        "                                        pth_transforms.Resize((int(bbox[3]), int(bbox[2]))),\n",
        "                                        pth_transforms.GaussianBlur(kernel_size=11, sigma=4),#pth_transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
        "                                        pth_transforms.GaussianBlur(kernel_size=11, sigma=4),\n",
        "                                        pth_transforms.GaussianBlur(kernel_size=11, sigma=4),#pth_transforms.GaussianBlur(kernel_size=3, sigma=0.5),\n",
        "                                      ])\n",
        "  attentions = transforms(attentions)\n",
        "  attentions = np.asarray(attentions).transpose(1,2,0)\n",
        "  org_size = (attentions.shape[0], attentions.shape[1])\n",
        "  attentions = attentions.reshape(-1, 12)\n",
        "\n",
        "  mask_part = clf.predict(attentions)\n",
        "\n",
        "  mask_part = mask_part.reshape(org_size)\n",
        "  pred_mask = np.zeros(dimensions, dtype=np.int8)\n",
        "\n",
        "  for i in range(mask_part.shape[0]):\n",
        "    for j in range(mask_part.shape[1]):\n",
        "      pred_mask[int(bbox[1]) + i, int(bbox[0]) + j] = mask_part[i, j]\n",
        "\n",
        "  seg, area = __get_annotation__(pred_mask)\n",
        "\n",
        "  annotation['pred_seg'] = seg\n",
        "  annotation['pred_seg']['counts'] = annotation['pred_seg']['counts'].decode()\n",
        "  annotation['pred_area'] = int(area)\n",
        "\n",
        "  pred_anns.append(annotation)\n",
        "  Ypred.append(pred_mask)"
      ],
      "metadata": {
        "id": "hBIUWLzP-Z_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "An0nnwWj1akV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import jaccard_score as IoU\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iouscores = []\n",
        "\n",
        "accscores = []\n",
        "\n",
        "tempgt = Ygt #\n",
        "temp = Ypred #\n",
        "\n",
        "for i in range(len(tempgt)):\n",
        "  gt = np.copy(tempgt[i])\n",
        "  pred = np.copy(temp[i])\n",
        "\n",
        "  iou = IoU(gt, pred, average='micro')\n",
        "\n",
        "  acc = accuracy_score(gt, pred)\n",
        "\n",
        "  accscores.append(acc)\n",
        "  iouscores.append(iou)"
      ],
      "metadata": {
        "id": "QQlzKXcLBmrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ = 0\n",
        "\n",
        "for i in range(len(iouscores)):\n",
        "  summ = summ + iouscores[i]\n",
        "print(summ)\n",
        "summ = summ/len(iouscores)\n",
        "\n",
        "print(summ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5dL_SonBqcP",
        "outputId": "c9cb2264-1a54-4e1b-d1d6-5dd2043108ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.38767501704155\n",
            "0.5529324221412742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summ = 0\n",
        "\n",
        "for i in range(len(accscores)):\n",
        "  summ = summ + accscores[i]\n",
        "print(summ)\n",
        "summ = summ/len(accscores)\n",
        "\n",
        "print(summ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzb5ZnfjBrq4",
        "outputId": "c482a730-dabf-4ed6-d65a-964e3d90735f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184.9843605324073\n",
            "0.722595158329716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "\n",
        "output_file = 'RESULTS_JSON'\n",
        "\n",
        "with open(output_file, 'w') as file:\n",
        "  json.dump(pred_anns, file, indent = 4, sort_keys=False)"
      ],
      "metadata": {
        "id": "MuG89qWOCSEm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}