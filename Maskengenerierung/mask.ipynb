{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "notebook um CNN zu definieren und mit attentionmaps von DINO zu trainieren und zu testen (teilweise auch evaluieren)"
      ],
      "metadata": {
        "id": "D9ZKRa7p-2pv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgL915d4uAab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HUz2IqPtfLz"
      },
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi\n",
        "\n",
        "!cd /content/cocoapi/PythonAPI && make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbTFt2YihL9B"
      },
      "source": [
        " !pip install timm\n",
        " \n",
        " !git clone https://github.com/Moldazien/BA.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyfQxEwgMg8R"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/BA')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4No_m7wkJtI2"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import cv2\n",
        "import random\n",
        "import colorsys\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import skimage.io\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms as pth_transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import utils\n",
        "import vision_transformer as vits\n",
        "\n",
        "from pycocotools.coco import COCO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbR6SMssJ3Yw"
      },
      "source": [
        "arch = 'vit_base' #'vit_small''vit_base'\n",
        "patch_size = 8\n",
        "output_dir = '/content/gdrive/MyDrive/Testing/first_test_dino'\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-aEiKdpeBZ2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def crop_fkt(bbox, area, percentile, width, height):\n",
        "  width = width\n",
        "  height = height\n",
        "  width_edge = bbox[2]*percentile\n",
        "  height_edge = bbox[3]*percentile\n",
        "  edge = (width_edge + height_edge)\n",
        "  tx = max(bbox[0]-edge, 0)\n",
        "  ty = max(bbox[1]-edge, 0)\n",
        "  bx = min(bbox[0]+bbox[2]+edge, width)\n",
        "  by = min(bbox[1]+bbox[3]+edge, height)\n",
        "  area = 80000\n",
        "  wid = bx - tx\n",
        "  hei = by - ty\n",
        "  p = np.sqrt(area/(wid*hei))\n",
        "  imagewidth = int(wid*p) - (int(wid*p)%8)\n",
        "  imageheight = int(hei*p) - (int(hei*p)%8)\n",
        "  img_size = (imageheight, imagewidth)\n",
        "  return (tx, ty, bx, by), img_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Uw4Q7zJgED"
      },
      "source": [
        "def gt_tensors(attentions, maskimg, bbox, width, height):\n",
        "  percentile = 0 \n",
        "  patch_size = 8\n",
        "  image_size = (480, 480)\n",
        "  area = 60000\n",
        "\n",
        "  box, img_size = crop_fkt(bbox, area, percentile, width, height)\n",
        "  crop_mask = maskimg.crop(box=box)\n",
        "  mask = np.asarray(crop_mask)\n",
        "  mask = torch.tensor(mask)\n",
        "  mask = mask.reshape(1, mask.shape[0], mask.shape[1]).float()\n",
        "  img_size = (285, 285)\n",
        "  transforms = pth_transforms.Compose([\n",
        "                                      pth_transforms.Resize(img_size, interpolation = InterpolationMode('nearest')),\n",
        "                                     ])\n",
        "  attentions = transforms(attentions)\n",
        "  mask = transforms(mask)\n",
        "  return attentions, mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVZpKj3i_j4B"
      },
      "source": [
        "# custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp1-15qH_jUY"
      },
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "class NACTI_seg(Dataset):\n",
        "  def __init__(self, annotations_file, dataset_dir, flip):\n",
        "    self.annotations_file = annotations_file\n",
        "    self.coco = COCO(annotations_file) \n",
        "    self.flip = flip\n",
        "    self.dataset = dataset_dir\n",
        "    self.img_ids = self.coco.getImgIds()\n",
        "    self.ann_ids = self.coco.getAnnIds()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ann_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    ann_id = self.ann_ids[idx]\n",
        "    ann = self.coco.loadAnns([ann_id])\n",
        "    img_id = ann[0]['image_id']\n",
        "    img = self.coco.loadImgs([img_id])\n",
        "\n",
        "    img_path = self.dataset + '/images/' + img[0]['file_name']\n",
        "    image = None\n",
        "    mask = None\n",
        "    bbox = None    \n",
        "    width = img[0]['width']\n",
        "    height = img[0]['height']\n",
        "\n",
        "    attentions_path = self.dataset + '/tensors/' + str(ann_id) + '_attention.pt'\n",
        "    attentions = torch.load(attentions_path)\n",
        "    mask = self.coco.annToMask(ann[0]) \n",
        "    bbox = ann[0]['bbox']\n",
        "\n",
        "    maskImg = Image.fromarray(mask)\n",
        "    attentions, mask = gt_tensors(attentions, maskImg, bbox, width, height)\n",
        "    attentions = attentions.to(device)\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    if self.flip: #bilder horizontal flippen um daten zu augmentieren\n",
        "      attentions = pth_transforms.functional.hflip(attentions)\n",
        "      mask = pth_transforms.functional.hflip(mask)\n",
        "    return attentions, mask, ann[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConcatSet(Dataset):\n",
        "  def __init__(self, dataset1, dataset2):\n",
        "    self.dataset1 = dataset1\n",
        "    self.dataset2 = dataset2\n",
        "    self.len1 = dataset1.__len__()\n",
        "    self.len2 = dataset2.__len__()\n",
        "\n",
        "  def __len__(self):\n",
        "    return (self.len1 + self.len2)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    attentions = None\n",
        "    mask = None\n",
        "    if idx < self.len1:\n",
        "      attentions, mask, ann = self.dataset1.__getitem__(idx)\n",
        "    elif idx >= self.len1:\n",
        "      attentions, mask, ann = self.dataset2.__getitem__(idx-self.len1)\n",
        "    return attentions, mask"
      ],
      "metadata": {
        "id": "t6wb4Q_Ct_6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainset1 = NACTI_seg('PATH_TO_ANNOTATION', 'PATH_TO_IMAGES', True) #datensatz mit geflippten bildern und masken\n",
        "#trainset2 = NACTI_seg('PATH_TO_ANNOTATION', 'PATH_TO_IMAGES', False) #datensatz mit normalen bildern mit masken\n",
        "\n",
        "#trainset =  ConcatSet(trainset1, trainset2)#datensätze zu einem zusammenfügen"
      ],
      "metadata": {
        "id": "3Eu5rw_YvN99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BiENw9Q_mjf"
      },
      "source": [
        "Netzwerke, fehlende schichten einfügen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reJL_iSwafnY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqilvCyif8-O"
      },
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      super(SimpleCNN, self).__init__()\n",
        "\n",
        "      self.conv1 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      #self.conv11 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv3 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv4 = nn.Conv2d(in_channels=12, out_channels=1, kernel_size=1, stride=1, padding=0, padding_mode='reflect')\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = F.relu(x)\n",
        "      #x = F.relu(self.conv11(x))\n",
        "      x = self.conv2(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv3(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv4(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoCJDtmDySrO"
      },
      "source": [
        "class UCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      super(UCNN, self).__init__()\n",
        "\n",
        "      self.conv1 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv3 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv4 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv5 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv6 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv7 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv8 = nn.Conv2d(in_channels=12, out_channels=1, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv2(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv3(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv4(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv5(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv6(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv7(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv8(x)\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HugePlus(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "      super(HugePlus, self).__init__()\n",
        "\n",
        "      self.conv1 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv11 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      #self.conv21 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv3 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv4 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      #self.conv41 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv42 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv5 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv6 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv7 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "      self.conv8 = nn.Conv2d(in_channels=12, out_channels=1, kernel_size=3, stride=1, padding=1, padding_mode='reflect')\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv11(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv2(x)\n",
        "      x = F.relu(x)\n",
        "      #x = self.conv21(x)\n",
        "      #x = F.relu(x)\n",
        "      x = self.conv3(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv4(x)\n",
        "      x = F.relu(x)\n",
        "      #x = self.conv41(x)\n",
        "      #x = F.relu(x)\n",
        "      x = self.conv42(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv5(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv6(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv7(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.conv8(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "6cva2tNbiPrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IR1lm4lrG8D"
      },
      "source": [
        "# for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhcsTfeSrXX5"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL-kVTF4rYAn"
      },
      "source": [
        "trainset1 = NACTI_seg('PATH_TO_ANNOTATION', 'PATH_TO_IMAGES', True) #datensatz mit geflippten bildern und masken\n",
        "trainset2 = NACTI_seg('PATH_TO_ANNOTATION', 'PATH_TO_IMAGES', False) #datensatz mit normalen bildern mit masken\n",
        "trainset =  ConcatSet(trainset1, trainset2)\n",
        "\n",
        "batch_size = 8 # 4 # 16 # 32\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyH6YeIKrgRb"
      },
      "source": [
        "net = UCNN()\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "#PATH = 'MODEL_PATH'\n",
        "#net.load_state_dict(torch.load(PATH))\n",
        "net.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX45XPiYq8bA"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.0001)  #für verschiedene lerningrates neues training starten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVOZvCQlrKBO"
      },
      "source": [
        "loss_graph = []\n",
        "\n",
        "for epoch in range(30):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, mask = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        loss = criterion(outputs, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        output_value = 50\n",
        "        if i % output_value == output_value - 1:    # print every 2000 mini-batches\n",
        "          print('[%d, %5d] loss: %.20f' %\n",
        "              (epoch + 1, i + 1, running_loss / output_value))\n",
        "          \n",
        "          loss_graph.append(running_loss / output_value)\n",
        "\n",
        "          running_loss = 0.0\n",
        "          #PATH = '/content/gdrive/MyDrive/models/channelislands/CNN' + str(i) + 'modelCNN.pth' #entfernt weil es sonst zu langsam ist\n",
        "          #torch.save(net.state_dict(), PATH)\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "PATH = 'MODEL_SAVE'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHU8KdYTlmLX"
      },
      "source": [
        "import matplotlib.pyplot as plt #loss printen\n",
        "y_values = np.asarray(loss_graph)\n",
        "x_values = np.arange(0,len(y_values),1)\n",
        "\n",
        "plt.plot(x_values, y_values)\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "_nGKba3o_RAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMixpvF6WwJT"
      },
      "source": [
        "# testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json, yaml\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import OrderedDict\n",
        "from pycocotools import mask as cocomask\n",
        "from pycocotools import coco as cocoapi\n",
        "\n",
        "def __get_annotation__(mask, image=None): #übersetzten einer binären maske in coco format um in json speichern zu können\n",
        "  labelMask = np.expand_dims(mask, axis=2)\n",
        "  labelMask = labelMask.astype('uint8')\n",
        "  labelMask = np.asfortranarray(labelMask)\n",
        "  Rs = cocomask.encode(labelMask)\n",
        "  assert len(Rs) == 1\n",
        "  Rs = Rs[0]\n",
        "  area = cocomask.area(Rs)\n",
        "  return Rs, area "
      ],
      "metadata": {
        "id": "raK2JEfaAdw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "class TestSet(Dataset):\n",
        "  def __init__(self, annotations_file, dataset_dir, flip):\n",
        "    self.annotations_file = annotations_file\n",
        "    self.coco = COCO(annotations_file)  #for fast reading\n",
        "    self.flip = flip\n",
        "    self.dataset = dataset_dir\n",
        "    self.img_ids = self.coco.getImgIds()\n",
        "    self.ann_ids = self.coco.getAnnIds()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ann_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    ann_id = self.ann_ids[idx]\n",
        "    ann = self.coco.loadAnns([ann_id])\n",
        "    img_id = ann[0]['image_id']\n",
        "    img = self.coco.loadImgs([img_id])\n",
        "    img_path = self.dataset + '/images/' + img[0]['file_name']\n",
        "    image = None\n",
        "    mask = None\n",
        "    bbox = None#\n",
        "    \n",
        "    width = img[0]['width']\n",
        "    height = img[0]['height']\n",
        "    attentions_path = self.dataset + '/tensors/' + str(ann_id) + '_attention.pt'\n",
        "    attentions = torch.load(attentions_path)\n",
        "    mask = self.coco.annToMask(ann[0])\n",
        "    #mask = np.zeros((3000,3000))  #falls keine maske vorhanden \n",
        "    bbox = ann[0]['bbox']\n",
        "    maskImg = Image.fromarray(mask)\n",
        "    attentions = attentions.to(device)\n",
        "    return attentions, mask, ann[0], bbox, (height, width)"
      ],
      "metadata": {
        "id": "zuJVHjb54mqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB0IJOIQf64i"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "testset = TestSet('/content/gdrive/MyDrive/Datasets/channelisland_test/annotations/annotations.json', '/content/gdrive/MyDrive/Datasets/channelisland_test', False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wctY50rzal2c"
      },
      "source": [
        "PATH = 'MODEL_PATH.pth'\n",
        "\n",
        "net = UCNN()\n",
        "net.to(device)\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "net.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = np.arange(0,testset.__len__(),1)\n",
        "\n",
        "# for per class evaluation\n",
        "#Ygt = []\n",
        "#Ypred = []\n",
        "#foxgt = []\n",
        "#fox = []\n",
        "#skunkgt = []\n",
        "#skunk = []\n",
        "#rodentgt = []\n",
        "#rodent = []\n",
        "#birdgt = []\n",
        "#bird = []\n",
        "\n",
        "\n",
        "pred_anns = []\n",
        "\n",
        "net.eval()\n",
        "\n",
        "for i in test_ids:\n",
        "  print(str(i) + ' von ' + str(len(test_ids)))\n",
        "  attentions, gtmask, annotation, bbox, dimensions = testset.__getitem__(i)\n",
        "  Ygt.append(gtmask)\n",
        "  output = net(attentions.reshape(1,12,attentions.shape[1],attentions.shape[2]))\n",
        "  transforms = pth_transforms.Compose([\n",
        "                                      pth_transforms.Resize((int(bbox[3]), int(bbox[2])), interpolation = InterpolationMode('nearest'))\n",
        "                                     ])\n",
        "  output = transforms(output)\n",
        "  output = output.reshape(output.shape[2],output.shape[3])\n",
        "  m = nn.Sigmoid()\n",
        "\n",
        "  output = output.detach()\n",
        "  output = output.to('cpu')\n",
        "  output = np.asarray(output, dtype=np.float32)\n",
        "\n",
        "  mask_part = np.copy(output)\n",
        "  mask_part[mask_part >= 0.5] = 1\n",
        "  mask_part[mask_part < 0.5] = 0\n",
        "  pred_mask = np.zeros(dimensions, dtype=np.int8)\n",
        "\n",
        "  for i in range(mask_part.shape[0]):\n",
        "    for j in range(mask_part.shape[1]):\n",
        "      pred_mask[int(bbox[1]) + i, int(bbox[0]) + j] = mask_part[i, j]\n",
        "\n",
        "  seg, area = __get_annotation__(pred_mask)\n",
        "\n",
        "  annotation['pred_seg'] = seg\n",
        "  annotation['pred_seg']['counts'] = annotation['pred_seg']['counts'].decode()\n",
        "  annotation['pred_area'] = int(area)\n",
        "\n",
        "  pred_anns.append(annotation)\n",
        "  Ypred.append(pred_mask)\n",
        "  ############################### für meanIoU pro klasse\n",
        "  if annotation['category_id'] == 1:\n",
        "    foxgt.append(gtmask)\n",
        "    fox.append(pred_mask)\n",
        "  if annotation['category_id'] == 2:\n",
        "    skunkgt.append(gtmask)\n",
        "    skunk.append(pred_mask)\n",
        "  if annotation['category_id'] == 3:\n",
        "    rodentgt.append(gtmask)\n",
        "    rodent.append(pred_mask)\n",
        "  if annotation['category_id'] == 4:\n",
        "    birdgt.append(gtmask)\n",
        "    bird.append(pred_mask)"
      ],
      "metadata": {
        "id": "Ulq-In7x-nn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt #visueller vergleich der berechneten masken mit ground truth masken\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "for i in range(len(Ypred)-220):\n",
        "  gt_mask = np.copy(Ygt[i])\n",
        "  pred_mask = np.copy(Ypred[i])\n",
        "\n",
        "  gt_mask[gt_mask == 1] = 255\n",
        "  pred_mask[pred_mask == 1] = 255\n",
        "\n",
        "  imgplot = plt.imshow(gt_mask)\n",
        "  plt.show()\n",
        "  imgplot2  = plt.imshow(pred_mask)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "cYdrAR-xEplp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#berechnen der metriken pro maske\n",
        "from sklearn.metrics import jaccard_score as IoU\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iouscores = []\n",
        "accscores = []\n",
        "\n",
        "tempgt = birdgt #rodentgt #skunkgt #foxgt #Ygt\n",
        "temp = bird #rodent #skunk #fox #Ypred\n",
        "\n",
        "for i in range(len(tempgt)):\n",
        "  gt = np.copy(tempgt[i])\n",
        "  pred = np.copy(temp[i])\n",
        "\n",
        "  iou = IoU(gt, pred, average='micro')\n",
        "\n",
        "  acc = accuracy_score(gt, pred)\n",
        "\n",
        "  accscores.append(acc)\n",
        "  iouscores.append(iou)"
      ],
      "metadata": {
        "id": "gJT96RG5DHSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ = 0\n",
        "\n",
        "for i in range(len(iouscores)):\n",
        "  summ = summ + iouscores[i]\n",
        "print(summ)\n",
        "summ = summ/len(iouscores)\n",
        "\n",
        "print(summ) #meanIoU"
      ],
      "metadata": {
        "id": "ZAYdYAjjSTvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summ = 0\n",
        "\n",
        "for i in range(len(accscores)):\n",
        "  summ = summ + accscores[i]\n",
        "print(summ)\n",
        "summ = summ/len(accscores)\n",
        "\n",
        "print(summ) meanPixelaccuracy"
      ],
      "metadata": {
        "id": "jo9bU2IRUbRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "\n",
        "output_file = 'RESULT_FILE.json'\n",
        "\n",
        "with open(output_file, 'w') as file:\n",
        "  json.dump(pred_anns, file, indent = 4, sort_keys=False)"
      ],
      "metadata": {
        "id": "084QRsA6ZN8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** weitere ausgaben zum vergleichen der verschiedenen ansichten (Attention, ausgabeschicht des CNN, Maske,...)**"
      ],
      "metadata": {
        "id": "ZNF4aPRb--XM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMpk1W9AWvpy"
      },
      "source": [
        "attentions, org_mask = testset.__getitem__(23)\n",
        "attentions = attentions.reshape(-1,attentions.shape[0],attentions.shape[1],attentions.shape[2])\n",
        "\n",
        "print(attentions.shape)\n",
        "\n",
        "output = net(attentions)\n",
        "\n",
        "output = output.reshape(output.shape[2],output.shape[3])\n",
        "\n",
        "m = nn.Sigmoid()\n",
        "\n",
        "output = m(output)\n",
        "\n",
        "org_mas = org_mask.detach().cpu()\n",
        "org_mas = np.asarray(org_mas)\n",
        "mask = output.detach().cpu()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "trans = pth_transforms.ToPILImage()\n",
        "img = trans(mask)\n",
        "\n",
        "\n",
        "org_mask1 = org_mask.reshape(org_mask.shape[1], org_mask.shape[2])\n",
        "org_mask1[org_mask1 == 1] = 255\n",
        "org_mask1 = org_mask1.cpu()\n",
        "org_mask1 = np.asarray(org_mask1)\n",
        "org = Image.fromarray(org_mask1)\n",
        "\n",
        "imgplot2  = plt.imshow(org)\n",
        "plt.show()\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "test = output.detach().cpu()\n",
        "mask = np.asarray(test)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "mask[mask >= 0.8] = 255\n",
        "mask[mask < 0.8] = 0\n",
        "\n",
        "img = Image.fromarray(mask)\n",
        "\n",
        "org_mask1 = org_mask.reshape(org_mask.shape[1], org_mask.shape[2])\n",
        "\n",
        "org_mask1[org_mask1 == 1] = 255\n",
        "\n",
        "org_mask1 = org_mask1.cpu()\n",
        "\n",
        "org_mask1 = np.asarray(org_mask1)\n",
        "\n",
        "org = Image.fromarray(org_mask1)\n",
        "\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "imgplot2  = plt.imshow(org)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck-nsvqwYu8d"
      },
      "source": [
        "mask = np.asarray(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "AI1IRs38cMsC",
        "outputId": "39d077a6-9cbe-4ca0-d053-c5373c216eab"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "mask[mask >= 0.8] = 255\n",
        "mask[mask < 0.8] = 0\n",
        "\n",
        "img = Image.fromarray(mask)\n",
        "\n",
        "org_mask1 = org_mask.reshape(org_mask.shape[1], org_mask.shape[2])\n",
        "\n",
        "org_mask1[org_mask1 == 1] = 255\n",
        "\n",
        "org_mask1 = org_mask1.cpu()\n",
        "\n",
        "org_mask1 = np.asarray(org_mask1)\n",
        "\n",
        "org = Image.fromarray(org_mask1)\n",
        "\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "imgplot2  = plt.imshow(org)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3RU9bn/8feTSYKEBAkgCpGI3GRhPSBwgCpqFUSLbdEqLYqCyAkI1SOLn0fxwoFqPYt6lPaAqFwP2LJAVCwKWgOIB0EbAUUIIJcAljvmIonhkmTm+f0xk5jAhNxmZk+yn9da35WZ7+zZ88nOzJN9+c7eoqoYY9wrxukAxhhnWREwxuWsCBjjclYEjHE5KwLGuJwVAWNcLmxFQERuF5FdIrJXRCaG63WMMXUj4RgnICIeYDdwK3AI2Ajcq6o7Qv5ixpg6CdeaQG9gr6ruU9UiYAkwOEyvZYypg9gwzTcFOFju/iGgT2UTi4gNWzQm/LJV9ZJzO8NVBKokIqOB0U69vjEu9G2wznAVgcNA23L3Lw/0lVHV2cBssDUBY5wUrn0CG4FOInKliMQDQ4H3wvRaxpg6CMuagKqWiMgjwEeAB5ivqtvD8VpuJyLYN0FNXYTlEGGNQ0Th5kDjxo3p1KlThb7i4mJ27tzpUKLzPfTQQ9xxxx3cc889VghMdWxW1V7ndloRKCctLY3k5GQALr/8ch599NEKj+fm5nLvvfeSnp7uRLygRowYQV5eHu+9Z1tbpkpBiwCq6ngD1MnWuHFjnTBhgp46dUqrMnfuXG3cuHFYcjRq1KjKaWJjYzUhIUETEhJ07Nixmp+fr8ePH9ePP/5Y33jjDY2Li3N0WVqL6rYp6OfP6QLgZBFo3769Dh48WH/44QctLi6usgCoqpaUlGhhYaHecsstIckQGxurAwcO1IEDB+oXX3xRdnvgwIHavn37CtPedNNNOmPGDD19+rSePn36vMxer1eXLl2qLVq0cPrNZi06mxWB0iYi+oc//EE3bNhQrQ9+MEeOHNFp06ZpampqnbI89dRT6vV6g77Ghg0bdNq0aWUtPz+/WtmWLVumv/vd75x+w1mLvuaeIpCcnKyXXHLJef2tWrXSNm3a6Ouvv64lJSXV+7RXITMzU1u2bFnjjHFxcfr0009XaxOkNj777DNNTEx0+k1nLbqaO4pAx44dNSMjQw8cOKAPPvhghXb06FH1+Xzq8/lC9mHz+Xy6adMmveqqq6qdUUR08uTJIc0RLNeTTz5Z4XVvu+02p9+E1pxt7igCDz30UNg+WBcyduxYFRENHOlQoOx+aZs+fbouXrxYlyxZokVFRWHPtGXLFp01a5bGxMTo2LFj9dixY/rAAw84/Ua05lwLWgQa1CHCyy67jN27d5OUlBSK2dXIDz/8wJkzZwCYPHkyeXl5TJ8+vcI0ycnJeDyeiOby+Xzk5uaSmJjIRRddxOnTp3n00UfZtGlT2TR5eXn885//jGgu44iGP06gTZs2HDp0CBEJxexcYe7cuaxatYqlS5c6HcWEX9Ai4Ni3CMOhcePGTkeod7p3786hQ4do0qQJp06dIhr+KZjIqvdrAh6Ph27dunH69GlWrlxJu3btbE2ghrxeLyUlJYwcOZIvv/ySXbt2OR3JhEfD3ByYMGEC48aNo6CggO7du4cylitt3ryZ9evXl92fOnUqx44dczCRCaGGN2z43nvv1dzc3DDsVzel9u3bpzNmzAjbUGlrdnQAqNuawCeffMJNN90UyjjmHKrKnDlzeOyxx8qOgJh6qeHsGBQRRITBgwfTtWtXp+M0eCJCWloaxcXFZd+sLL/fRX9cozP1UL0sArNmzeKuu+6icePGNGnSxOk4riAijBkzhpiYGDp27Mi1115b9tibb77JI4884mA6Uxf1qggkJiby7//+7/Tp04eWLVs6Hcd1YmNjGTt27Hn9iYmJDqQxoRL1RaBRo0Z88MEHxMXFER8fT+/eve0QYBTJzc1l2rRpTscwdRB1RSAlJYVu3bqV3W/UqBH9+vUjPj7ewVSmMsnJyTz22GNMnz6dnTt3UlRU5HQkU0NRUQTatm3L448/DkCXLl0YOHCgw4lMdYkIHo+Hyy67jFtvvZWXXnqJuLg4pk6dSmzsj28vVeWZZ56hsLDQwbQmqGDHDSPdevbsGZ6D3CYiFixYoIC2adNGAU1NTdUzZ85UmMbn82lWVpbu3r1bBw0a5PTxcre2oOMEomJNwNRvnTp1okOHDmRlZQGwYMGC8zbfRIT27dsD/qMJLVq0sE2HKGFFwNTYc889h4gwadIkAK677joWLVpU9nXkq6+++oI7b0WEmJhwXffG1JQVAVNjR48ePe9D3KdPH/r0qfSasxUkJCSwfPlynn76aTIzMzl79mw4Yppqiophw7169dLyJ7kw7tGlSxcuuugifvGLX3Ds2DHmzZvndKSGrOEMGzYNx6JFi2jatCmdOnXihx9+wOPxMHv2bKdjhV1sbCxPP/00t95663mPjRw5kr1790YuS8ReyZggevbsWXY7MTGRK664Ao/HQ48ePdi4caODyfz69+9PQkJChb5169Zx8uRJAJo0acItt9xS9tg333zDnj17yu6XPp6RkcGJEycAiIuL47nnnuOJJ54Ium+kf//+ES0Cdf0K8AFgG7CFwOEHoDmwCtgT+Jlc1XzsEKEptXHjRn399dc1KytLb7rpJqcPqen+/fvPy/jmm2/qjBkzdMaMGfrGG29UeOyZZ56p8PzOnTurquq7776r8fHx+stf/lLnzJlzwTNNnzp1Sh988MGIHSIMRRFoeU7fi8DEwO2JwB+rmo8VARPMiRMntHfv3hH5sLds2VJTU1M1NTVV33//fd2zZ4/u2bOnxmeF/u///u+y+aSmpuqmTZtU9cdxEtU9/0V+fr7+27/9m7Zu3bpeFoFdQOvA7dbArqrm07FjxxotaOMeOTk5esMNN4Ttw5+UlKRpaWn61VdflV2Toi7Xgyg/j1DMa/v27WEvAnXdJ6BAeuCkILNUdTZwqaoeDTx+DLi0qpkcP368jjFMOPh8PlSVmJgYx7601bx5c0aMGMH69etDcs4CESExMZG5c+fi8Xho0qQJt99+ewiS/jj/UM6rdFg2+Mdf/Od//mfZ4zNnzmTt2rV1f6FglaG6DUgJ/GwFfA3cCHx/zjR5lTx3NLAJ2HTRRRfVulqa8Jk1a5Z269YtrFdKqo4zZ87ohAkTtGvXrrX+L9ixY0ft1auX/vnPf9a8vDzHf6fqKikp0dzcXM3NzT3vWpQFBQXaqlUrZzcHtOKHegrwOLXYHEhKSgrTIjSl/va3v+nMmTNr9Jz09HS95pprKr1gaqQdPnxYJ02apG3btq32G/+RRx7RSZMm6Y4dO5yOH3I+n0//+Mc/6oABA+pUBGo9WEhEmgAxqloQuL0KeA7oD+So6lQRmQg0V9UnLjSv2NhY7d27N4sWLeLKK6+sVR5zYWPHjuXtt9+mU6dOxMXF8e6779K8efNKp9+yZQt33XUXp06dCjpC8FxTp07lk08+YciQIYwaNSrU8SvIzMwkPz+/WtP26NGDiy66KKx5nHbkyBHuvPPO6hxSDe3ZhoH2+DcBvga2A88E+lsAa/AfIlyNvwhUNS8FNDMzM+zV061KSkp069atZf8Vunfvrrt37650eq/Xq3PnztXhw4dXa9W5pKREi4qKQna1Z1Mz1VwbCO2OQVXdB3QL0p+Df23AOOxvf/sb6enpZffz8vLKbm/ZsoXhw4fz9ttvk5KSct5zY2JiGDVqVJX/1Z9//nmOHj3KyJEjadOmDS+88ALjxo1j/fr1PPzww6H7ZUz4BKsMkW7YmkBYlL80+YsvvqgfffTRef8dtm7dWqfXKN1Zd+mll+qRI0c0KytLs7OztVmzZjpv3rwQ/SbmQr7//nvt16+fY4cITT2RmZkZ9Kw+p0+fZs2aNfTv35/c3Fx27drFT3/60xrP/8SJE3g8Htq3b09hYSGnT58uG1prQmvp0qXk5uaW3V+1alWFq0bVVFQVgcmTJ/PWW2/ZiURDJCYmBo/Hg8/nY9GiRUGnefzxxzlw4AALFy5k5syZtGvXrkZFINgOQxGhZ8+e/PKXv6x1dlO5559/nszMzJDNL6rO7LBhwwanIzQokyZNIisriyeffJLs7Gy+/PJLUlNTAWjatCl9+vRh0qRJHDp0iLVr19Zq4MmKFSvo0KEDAF9++SX//Oc/ady4Menp6XTs2DGkv48Jk2DbCJFuBLZZnnjiiXoziKO++uyzz3Ty5Mm6YMECVVV98cUXK2w3/vSnP9Xnn3++RmPmS88x2KpVK01PTw9XdKP+sRs1HCAUvnECoVR6LcKMjAz+9V//1TYHImjr1q2cOnWq7P4777xDhw4dGD16dLVPAfbdd9+RlZVFQkIC//Iv/xKuqK7k9XopKCiguLiYu+++m71793L06NGqnxhc9F+aPCUlhYMHD1oRcNCuXbto1qwZl15a5Vc+TAh5vV5WrlyJ1+ut0H/48GHGjx9fNk0dRf+ZhULwS5o6ev/99+nWrVvQM96Y0Fq4cCGff/454H/vL1iwgJKSkojniKoiYJx38cUX88ILL3DjjTfSqFEjp+M0aL179wbgwQcfdDRHVG0OXHbZZRw5csQ2BxxU+n6wv0HoHTlyhOXLl5fdf+ONN/jHP/4RyQjRvzlgnFfXD/+yZcvo1KkT11xzTYgSRT+fz4fP58Pj8SAilJSUVCimMTExFBUVMWLECFavXu1w2vNF1TiB4uLiyJ5g0YRUYWEhq1evJjs72+koETV37lxatWrF2rVr+eyzz+jduzctW7akZcuWjBw5klmzZtGqVauoLAAQZUUgJyeHP/zhD07HMLWUlZXFa6+95nSMiCsqKiIvL4/+/ftz/fXX88033zBw4EDy8/Np2bIly5cvp6CgwOmYlYqqzYEWLVpUOH2SMdGkpKSEmTNnnjcEu/RU4qWKior46quvAPjzn/8csXy1FVVF4JZbbim7aKUx0SIrK4stW7awa9cunn32Warame71essuzlofRE0RuOeee5g1a5btlTZR469//Suffvop27dvb9Dfa4maItC3b1+Sk5OdjmFcLjc3t+zkK507d+bxxx9v8GfDjpoiYIyTPvjgA/bv38/KlSv58MMPnY4TUVFTBObPn8+QIUPKvupq6qfY2Nh6sUnn8/l47bXX+Oqrr7jzzjtJS0vj2LFjTsdyRFSNGFy6dCn33HMPe/bs4bvvviMlJYV27do5nM5Ul9frpbCwkISEBGJjo+b/S1Dvv/8+d999NyUlJcTHx3P27FmnI0VC0BGDUTVOYOTIkSxbtozMzEwGDhzoymPO9ZnH46Fp06ZRXwAAOnXqRPfu3VFVtxSASkVVESgsLGTMmDH4fD5WrFjBsGHDGDVqFL169aJXr15s27atysMzxlQlPz+fVq1a8ZOf/MTpKFEhqjYHyt0v2670+Xxl/S1atOD111+vdD633XYbSUlJYUppGorrrruOjIyM8me2cov68wWiyv44OTk5DBkypNLn7dy5k6uuuqpe7JgykVX6flqxYgV79+6t8M/F7aJqc6Cubr75ZsaMGRPV47SNMyZPnsz111/P/fffz3fffed0nKgSlWsCtXXs2DHmzJmD1+vllVdeoXHjxk5HMlFiypQplJSUlJ3Jx/woKvcJ1FSPHj34/e9/D8DHH3/Mq6++yuHDh2nRokVI8pn6S1VZuXIlr732Gunp6Y6cviuKRP+JRmsjJiaGxx57jGnTpgH+cxKcOXOGxMRE2zdg+Pbbb7nqqqtcfxgwoHbjBERkvoicEJHMcn3NRWSViOwJ/EwO9IuITBeRvSKyVUR6hPZ3OJ/H4+Hqq68uux8XF0dSUpIVAAP4T/hhBeDCqrNjcAFw+zl9E4E1qtoJ/2XIJwb6fw50CrTRQNhH+xQXF/PWW2+F+2WiVn5+/nlHUgoKCtx26Os8RUVFTJkyhRdffNHpKFGvyiKgquuA3HO6BwMLA7cXAneW638jcLGUfwDNRKR1qMIG87Of/Ywbb7wxnC8RtbZu3cqAAQPO+8APHz68wgVF3Ojvf/87v//97ykqKnI6StSr7dGBS1W19DIox4DSK1WkAAfLTXco0HfeJVNEZDT+tYVaadu2LZMnT2bQoEG0bh3WOhO1ioqKKpzUstS4ceOIj493KJXzXDgIqE7qfIhQVbU2O/ZUdTYwG2q3Y7B58+aMGjWqpk9rUHr16kWzZs04duwYKSkpZf1uvnBITk4O9913H5s3b3Y6Sr1R28FCx0tX8wM/S0+ydhhoW266ywN9Jkx+/vOfs2rVKqdjRIXjx4/zwAMPkJ6eTk5OjtNx6o3argm8B4wApgZ+Li/X/4iILAH6ACfLbTaYMPiP//gPpyM4zuv1UlxczPDhw0lPT3c6Tr1TnUOEi4HPgatE5JCIjML/4b9VRPYAAwL3AT4A9gF7gTnAuHCE7tKlCz179gzHrE09c+bMGZ599llatGhhBaCW6uVgocWLFzN06NBwxTH1yLfffmsnnqm+6D+piDE1MXXqVO644w6nY9R7VgRMvXT48GHWrl3L9u3bnY5S79XLIjBr1iz7urCLnTlzhoceesj2AYRIvSwC//d//2cXLnWx/fv38/HHHzsdo8Gol0VAVfnFL37Bn/70Jw4dOuR0HBNBGRkZ3HHHHW7/SnBI1csiAHDkyBEmTJjAfffd5/px8m6yatUq9u/f73SMBqXeFoFSn332Gf/1X//ldAwTAQUFBVYAwqBejhMor0mTJuTk5NCoUaNQRjJRaPPmzfTqdd5hblN9DXOcwOnTpxk3bhzfffcdOTk59u2xBsrr9fLwww87HaNBqvdrAuXmQXJyMitXrqRv376hiGWiiNfr5ZJLLim7YrCplYa5JlBKVcnNzWX27NlORzGmXmkwRaDU999/T35+vtMxTAjl5eUxbNgwvv/+e6ejNEgN6roDAO+++y5JSUm8/vrrdt2BBuB///d/+fvf/87SpUudjtJgNZh9AuXFxMRw/PhxWrZsGcrZmgibPXs2EyZMoLCw0OkoDUXD3idgGp4HH3yQyy67zOkYDV6D2xww9d/Zs2eZMmUKXq+X3NxzT3RtQs2KgIkqhYWFjBo1iqVLl9qYjwhpkJsDqsqaNWucjmFqYfr06bz55ptWACKowRaBsWPH2n+Tesj+XpHXIIsA+I8tP/TQQ7z11lv2xjLmAhr0PoHS7cs777yT+Ph4CgoKmDVrVtnjffv2pV+/fg4mNMZ5DboIgP8LRs8++ywpKSm8/fbbrF+/vuyxJ598kuuuu46YmAa7QmRMlRp8EfB6vbz88suICF6vt8JjL7/8MqmpqTz88MNWCKJEu3btuPjiizl58qTTUVyjQY4YrInExERycnJcfQHPaHPDDTdUWGMzIWMjBoM5deoU48aNC8spyhYuXMg333wT8vk2ZIWFhXY58Qhr8JsDVfH5fMybN4/i4mJ+9atf8etf/xpVZenSpRQVFREXF8dvf/vbWm0uDB8+PAyJG6Z169bRu3dv/ud//ocvvvjC6TjuUnotdycboNHQEhIS9P7779f77rtP4+LiFNDY2Fi99957ddiwYbpt2zYdNmyYbty4UU3ofPLJJ3rFFVfoPffco926dXP8fdCA2yYN9vkL1qkVP6Dz8V96PLNc3xT8lxzfEmiDyj32FP4Lku4Cbqtq/hpFRaBVq1a6evVq7devX9DHk5OTNTk5WVevXl3lG7uwsFC3bdumhYWFIfuwNFTz5s1z/G/vkha0CFRnHXcBcHuQ/j+pavdA+wBARLoCQ4GrA895VUQ81XiNqHDixAkGDBhQ6U6pvLw8OnfuTNu2bauc19dff80111xDZmZmqGMaE1JVFgFVXQdU96tcg4ElqnpWVffjXyPoXYd8UScjI6Na17/r2rUra9asoUuXLhFIZUzt1eXowCMislVE5otIcqAvBThYbppDgb7ziMhoEdkkIpvqkMERW7dupbi4+ILTXHzxxdxyyy00bdo0QqnqpzNnzrBjxw6nY7habYvAa0AHoDtwFHi5pjNQ1dmq2kuDHLeMds8//7yd7SZEcnJyePnlGr99TAjVqgio6nFV9aqqD5jDj6v8h4HyG8yXB/qMMVGqVkVARFqXu3sXULr36z1gqIg0EpErgU6AHfQ1JopVOVhIRBYDPwNaisghYDLwMxHpjv+wwwFgDICqbheRpcAOoAT4nap6g823vhER+0pyiKkqL7zwgtMxTLDjhpFuOH/8tNIWExOjY8aM0RMnTujNN9+sgHo8Hs3LywvloXLXOXnypKalpanH43H8b+yiVrvBQpFoUbBwKm1NmzbVoqIiVVXNycnRgQMHqsfj0R07duinn34atg9JQ/fhhx86/rd1YQtaBFz/3YGaKCoq4sCBA3i9XoYOHcrJkyf5yU9+wvLly/F46s2YKMepKmfPnnU6hgmwIlCFkpISVq1ahcfj4fjx4+zevRvwjxUAyM7O5quvvrJLZtfAqVOnGDZsmNMxTKlgqweRbji/mlSn1qFDBx0/frxmZ2eHcQW64Zg2bZrGxMQ4/ndzYQu6OeD6k4qE0vXXX8+KFSto1qyZ01Gi2k033cS6deucjuFGdlKRcNuwYQNPPfWU0zGMqRErAiai9MdNQBMlbMdgiGVnZ7NlyxYSEhLo3Lmz03GiQk5ODgcP+r9XtnjxYj7//HOHE5kKgu0oiHTD+R0mIW9t27a1cQSqmp+fr3fffbfjfw9rKHU4qYiphYMHD9r1EPGfqOWdd95xOoa5ACsCJmx27tzJrbfe6nQMUwUrAiYsdu7cyX333cf+/fudjmKqYEUgjGbMmMGaNWvIyclxOkrEpaamsnjxYq688kqno5gqWBEIo5ycHAYMGEBaWprTUSKuSZMmdOnShUaNGjkdxVTBioAxLmdFwBiXsyJgjMtZEYiAdevWccMNNzBkyBAKCgooKSk5bxpV5dFHH+XMmTMOJDSuFmwEUaQbzo+kiljr2LGjZmRkqKrqrl279KOPPlKfz6c+n09TU1N18ODBevz48XAN4Iu4Ll26OL7MrZU1O7NQNBg4cCC9e/dm37593H///WzdupW0tDREhNzcXJYvX46IsGTJEtuzbiLCioBDjh49ysaNGwF45ZVXKjy2YsUKDh8+TPv27Z2IFjIvvPACWVlZTscwVbB9AhG2Y8cOvv322wtOU1JSwm233cbcuXP5y1/+UuVXb/ft28fcuXOj7qpI2dnZVV6uzUSBYNsIkW44v60U0Xb99deXnb68qhYfH68vvfSS+ny+su1sn8+nmZmZumzZMlVVXbJkiQKalpamXq835Nv1F1JSUlLpa44fP97xZW2tQrNvEUaLDRs2sHbt2mpNW1RUxFNPPcVf//rXsr7i4mL69+/PmjVrOHXqVFn/vHnzSEtL4+TJkyHPfK78/Hw2bdpEz549GTp0qCuHRjcUtk+gHiguLmbZsmVlmxFer5e8vDxmzpyJqpKdnQ2Az+dj/vz5DBkyhNtvvz3kOU6cOMHs2bMByMrKYsGCBQB8/fXXAAwYMIDRo0eH/HVNeNmJRuu5pKQklixZgojwwAMPkJOTQ9euXUlOTmbkyJH85je/ITY2lsaNGwd9vs/nu+C+hIcffris+BQWFrJly5ZKp7366qsrnDVo4sSJvPrqq7X8zUwYBD3RqBWBBiA21r9Cd+4gpJiYGGJiYrjhhhsYP348SUlJ3HzzzWWP79ixg82bNzNq1KhKdz4GG9hUnSzgLzA+n69GzzdhFbQIVGenXVtgLf6LjG4HHgv0NwdWAXsCP5MD/QJMB/YCW4Ee1XgNp3eYNMj2q1/9SlNSUsruJycn6zvvvKOq/oFK1157reMZrUW01e5ahEBrAh9kIAnYDXQFXgQmBvonAn8M3B4EfIi/GPQFMqwIONOaN2+u8fHxFfpGjRqlBw4c0MWLFzuez1rEW2guSAosB24FdgGtyxWKXYHbs4B7y01fNp0VAWvWHG11P0QoIu2Aa4EM4FJVPRp46BhwaeB2CnCw3NMOBfqMMVGo2ocIRSQReAcYr6r5IlL2mKpqTXfuichowI4nGeOwaq0JiEgc/gKwSFWXBbqPi0jrwOOtgROB/sP4dyaWujzQV4GqzlbVXkH3VhpjIqbKIiD+f/nzgJ2qOq3cQ+8BIwK3R+DfV1DaP1z8+gIny202GGOiTJXjBESkH/ApsA0oPej7NP79AkuBVOBb4DeqmhsoGq8AtwOngJGquqmK16jRpoQxplZssJAxLmeXJjfGnM+KgDEuZ0XAGJezrxKbOrnmmmtISEhg7969dk6BesqKgKmTxYsXU1xczPDhw60I1FO2OWDqpLCwkJSUFFq3bu10FFNLVgRMnQwaNIj169dz+vRpp6OYWrJxAsa4h40TMMacz4qAMS5nRcAYl7MiYIzLWREwxuWsCBjjclYEjHE5KwLGuJwVAWNczoqAMS5nRcAYl7MiYIzLWREwxuWsCBjjclYEjHE5KwLGuJwVAWNczoqAMS5nRcAYl6vOVYnbishaEdkhIttF5LFA/xQROSwiWwJtULnnPCUie0Vkl4jcFs5fwBhTN9W57kAJ8P9U9UsRSQI2i8iqwGN/UtWXyk8sIl2BocDVQBtgtYh0VlVvKIMbY0KjyjUBVT2qql8GbhcAO4GUCzxlMLBEVc+q6n5gL9A7FGGNMaFXo30CItIOuBbICHQ9IiJbRWS+iCQH+lKAg+WedogLFw1jjIOqXQREJBF4BxivqvnAa0AHoDtwFHi5Ji8sIqNFZJOIbKrJ84wxoVWtIiAicfgLwCJVXQagqsdV1auqPmAOP67yHwbalnv65YG+ClR1tqr2CnYxBGNM5FTn6IAA84CdqjqtXH/5i8/dBWQGbr8HDBWRRiJyJdAJ+CJ0kY0xoVSdowPXAw8A20RkS6DvaeBeEekOKHAAGAOgqttFZCmwA/+Rhd/ZkQFjopddi9AY97BrERpjzmdFwBiXsyJgjMtZETDG5awIGONyVgSMcTkrAsa4nBUBY1zOioAxLmdFwBiXsyJgjMtZETDG5awIGONyVgSMcTkrAsa4nBUBY1zOioAxLmdFwBiXsyJgjHrjOvUAAAOBSURBVMtZETDG5awIGONyVgSMcTkrAsa4nBUBY1zOioAxLmdFwBiXsyJgjMtZETDG5awIGONyVgSMcTkrAsa4XKzTAQKygcLAz2jREstzIdGWB6IvU7TluSJYp6hqpIMEJSKbVLWX0zlKWZ4Li7Y8EH2Zoi1PZWxzwBiXsyJgjMtFUxGY7XSAc1ieC4u2PBB9maItT1BRs0/AGOOMaFoTMMY4wPEiICK3i8guEdkrIhMdynBARLaJyBYR2RToay4iq0RkT+BncpgzzBeREyKSWa4vaAbxmx5YZltFpEeE8kwRkcOB5bRFRAaVe+ypQJ5dInJbGPK0FZG1IrJDRLaLyGOBfkeW0QXyOLaMak1VHWuAB8gC2gPxwNdAVwdyHABantP3IjAxcHsi8McwZ7gR6AFkVpUBGAR8CAjQF8iIUJ4pwONBpu0a+Ns1Aq4M/E09Ic7TGugRuJ0E7A68riPL6AJ5HFtGtW1Orwn0Bvaq6j5VLQKWAIMdzlRqMLAwcHshcGc4X0xV1wG51cwwGHhD/f4BNBOR1hHIU5nBwBJVPauq+4G9+P+2ocxzVFW/DNwuAHYCKTi0jC6QpzJhX0a15XQRSAEOlrt/iAsvyHBRIF1ENovI6EDfpap6NHD7GHCpA7kqy+DkcnsksHo9v9wmUkTziEg74FoggyhYRufkgShYRjXhdBGIFv1UtQfwc+B3InJj+QfVvz7n6GGUaMgAvAZ0ALoDR4GXIx1ARBKBd4Dxqppf/jEnllGQPI4vo5pyuggcBtqWu395oC+iVPVw4OcJ4F38q2nHS1cfAz9PRDrXBTI4stxU9biqelXVB8zhx9XZiOQRkTj8H7hFqros0O3YMgqWx+llVBtOF4GNQCcRuVJE4oGhwHuRDCAiTUQkqfQ2MBDIDOQYEZhsBLA8krkCKsvwHjA8sAe8L3Cy3Cpx2JyzTX0X/uVUmmeoiDQSkSuBTsAXIX5tAeYBO1V1WrmHHFlGleVxchnVmtN7JvHvxd2Nf2/pMw68fnv8e22/BraXZgBaAGuAPcBqoHmYcyzGv/pYjH97cVRlGfDv8Z4ZWGbbgF4RyvOXwOttxf+mbl1u+mcCeXYBPw9Dnn74V/W3AlsCbZBTy+gCeRxbRrVtNmLQGJdzenPAGOMwKwLGuJwVAWNczoqAMS5nRcAYl7MiYIzLWREwxuWsCBjjcv8fAx4VUWn1ENgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}