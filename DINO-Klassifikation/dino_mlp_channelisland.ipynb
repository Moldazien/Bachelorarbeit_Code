{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgL915d4uAab"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HUz2IqPtfLz"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi\n",
        "\n",
        "!cd /content/cocoapi/PythonAPI && make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbTFt2YihL9B"
      },
      "outputs": [],
      "source": [
        " !pip install timm\n",
        " \n",
        " !git clone https://github.com/Moldazien/BA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyfQxEwgMg8R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/BA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFWM2uT369E_"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/dataset   #kopieren der featurevektoren um schneller trainiren zu können\n",
        "!cp -R /content/gdrive/MyDrive/Datasets/channelisland/features /content/dataset/features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4No_m7wkJtI2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import cv2\n",
        "import random\n",
        "import colorsys\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import skimage.io\n",
        "from skimage.measure import find_contours\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Polygon\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms as pth_transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import utils\n",
        "import vision_transformer as vits\n",
        "\n",
        "from pycocotools.coco import COCO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class Test_Dataset(Dataset):\n",
        "  def __init__(self, annotations_file, dataset_dir):  \n",
        "    self.annotations_file = annotations_file\n",
        "    self.coco = COCO(annotations_file) \n",
        "    self.dataset = dataset_dir\n",
        "    self.ann_ids = self.coco.getAnnIds()\n",
        "    self.img_ids = self.coco.getImgIds()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ann_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    ann_id = self.ann_ids[idx]\n",
        "    ann = self.coco.loadAnns([ann_id])\n",
        "    img_id = ann[0]['image_id']\n",
        "    img = self.coco.loadImgs([img_id])\n",
        "    fileN = img[0]['file_name'].split('/')\n",
        "    classN = fileN[0]\n",
        "    name = classN.split('.')[0]\n",
        "    feature_path = self.dataset + '/features/' + name + '_feature.pt'\n",
        "    features = torch.load(feature_path, map_location=torch.device('cpu'))\n",
        "    ground_truth = ann[0]['category_id']\n",
        "    gt_vect = np.zeros(4)\n",
        "    gt_vect[ground_truth-1] = 1\n",
        "    gt_vect = torch.tensor(gt_vect)\n",
        "    return features, ground_truth, ann[0]"
      ],
      "metadata": {
        "id": "5-jN7Ncy1dsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class Train_Dataset(Dataset):\n",
        "  def __init__(self, annotations_file, dataset_dir):  #taxonomy must be: kingdom phylum class order family genus name\n",
        "    self.annotations_file = annotations_file\n",
        "    self.coco = COCO(annotations_file)  \n",
        "    self.dataset = dataset_dir\n",
        "    self.img_ids = self.coco.getImgIds()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_id = self.img_ids[idx]\n",
        "    img = self.coco.loadImgs([img_id])\n",
        "    ann_ids = self.coco.getAnnIds([img_id])\n",
        "    anns = self.coco.loadAnns(ann_ids)\n",
        "    fileN = img[0]['file_name'].split('/')\n",
        "    classN = fileN[0]\n",
        "    direcN = fileN[1]\n",
        "    imgN = fileN[2].split('.')[0]\n",
        "    feature_path = self.dataset + '/features/' + classN + '/' + direcN + '/' + imgN + '_feature.pt'\n",
        "    features = torch.load(feature_path, map_location=torch.device('cpu'))\n",
        "    ground_truth = 0\n",
        "    if len(anns) > 0:\n",
        "      ground_truth = anns[0]['category_id']\n",
        "    gt_vect = np.zeros(4)\n",
        "    gt_vect[ground_truth-1] = 1\n",
        "    gt_vect = torch.tensor(gt_vect)\n",
        "\n",
        "    return features, gt_vect"
      ],
      "metadata": {
        "id": "a0Vezkbw1tzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgmHg8XqVoPV"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/dataset'\n",
        "\n",
        "test_path = 'PATH_TO_DATASET'\n",
        "\n",
        "trainset = Train_Dataset('TRAIN_ANNOTATIONS', dataset_path)\n",
        "testset = Test_Dataset('TEST_ANNOTATIONS', test_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDno7KwGVx98"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(7)\n",
        "\n",
        "train_ids = np.arange(0,trainset.__len__(),1)\n",
        "test_ids = np.arange(0,testset.__len__(),1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ger5houTkWD0"
      },
      "source": [
        "modelle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9w7-X1fkVYA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP_net(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, output_size):\n",
        "      super(MLP_net, self).__init__()\n",
        "\n",
        "      self.lin1 = nn.Linear(input_size, input_size, bias=True)\n",
        "      self.lin2 = nn.Linear(input_size, input_size, bias=True)\n",
        "      #self.lin2plus = nn.Linear(input_size, input_size, bias=True)\n",
        "      #self.lin2plusplus = nn.Linear(input_size, input_size, bias=True)\n",
        "      #self.lin3 = nn.Linear(input_size, int(input_size/2), bias=True)\n",
        "      self.lin3plus = nn.Linear(int(input_size/2), int(input_size/2), bias=True)\n",
        "      self.lin3plus1 = nn.Linear(int(input_size/2), int(input_size/2), bias=True)\n",
        "      self.lin4 = nn.Linear(int(input_size/2), output_size, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.lin1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.lin2(x)\n",
        "      x = F.relu(x)\n",
        "      #x = self.lin2plus(x)\n",
        "      #x = F.relu(x)\n",
        "      #x = self.lin2plusplus(x)\n",
        "      #x = F.relu(x)\n",
        "      #x = self.lin3(x)\n",
        "      #x = F.relu(x)\n",
        "      x = self.lin3plus(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.lin3plus1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.lin4(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4nw8LLbk-c9"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "dataset_path = '/content/dataset'\n",
        "\n",
        "trainset = Train_Dataset('TRAINSET_ANNOTATIONS.json', dataset_path)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoGHBwPllAeT"
      },
      "outputs": [],
      "source": [
        "net = MLP_net(768, 4) #anzahl der klassen ist 4\n",
        "\n",
        "net.to(device)\n",
        "\n",
        "#PATH = 'PATH_TO_MODEL'\n",
        "#net.load_state_dict(torch.load(PATH))\n",
        "net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCAf-MNQlB4T"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0BH2jSklEDu"
      },
      "outputs": [],
      "source": [
        "loss_graph = []\n",
        "\n",
        "for epoch in range(30):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, mask = data\n",
        "        inputs = inputs.to(device)\n",
        "        numb_inst = inputs.shape[0]\n",
        "        mask = mask.to(device)\n",
        "        mask = mask.type(torch.float32)\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        outputs = outputs.reshape((numb_inst, 4))\n",
        "        loss = criterion(outputs, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        output_value = 5000\n",
        "\n",
        "        if i % output_value == output_value - 1:    # print every out_value mini-batches\n",
        "          print('[%d, %5d] loss: %.20f' %\n",
        "              (epoch + 1, i + 1, running_loss / output_value))\n",
        "          \n",
        "          loss_graph.append(running_loss / output_value)\n",
        "\n",
        "          running_loss = 0.0\n",
        "          PATH = '/content/gdrive/MyDrive/models/channelislands/MLP' + str(i) + 'model_mlp.pth'\n",
        "          #torch.save(net.state_dict(), PATH) #entfernt weil zu langsam\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "PATH = 'MODEL_SAVE.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFkATBrK1-H3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_arr = np.asarray(loss_graph)\n",
        "x_val = np.arange(0, len(loss_graph), 1)\n",
        "\n",
        "plt.plot(x_val, loss_arr)\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n_Rt8FI8Nu1"
      },
      "source": [
        "**Testing**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#net = MLP_net(768, 4)\n",
        "\n",
        "#PATH = 'MODEL_PATH.pth'\n",
        "#net.to(device)\n",
        "#net.load_state_dict(torch.load(PATH))\n",
        "net.eval()"
      ],
      "metadata": {
        "id": "o-qajBJz8Mxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ3DfdUCG5eG",
        "outputId": "3e763c12-237d-4a06-f9c4-44419081bb70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "drive.flush_and_unmount()\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcZ1b9VgejeV"
      },
      "outputs": [],
      "source": [
        "Ygt = []\n",
        "Ypred = []\n",
        "\n",
        "pred_anns = []\n",
        "\n",
        "net.eval()\n",
        "\n",
        "for i in test_ids:\n",
        "  print(i)\n",
        "  features, gt, annotat = testset.__getitem__(i)\n",
        "\n",
        "  #features = features.reshape(1, -1)\n",
        "  features = features.reshape(768)\n",
        "\n",
        "  #print(features[:4])\n",
        "\n",
        "  #npfeatures = np.asarray(features)\n",
        "\n",
        "  Ygt.append(np.asarray(gt, dtype=np.float32))\n",
        "  features = features.to(device)\n",
        "  pred = net(features)\n",
        "\n",
        "  pred = F.softmax(pred, dim = 0)\n",
        "\n",
        "  pred = pred.detach()\n",
        "  pred = pred.to('cpu')\n",
        "\n",
        "  prediction = np.asarray(pred, dtype=np.float32)\n",
        "\n",
        "  top = np.amax(prediction)\n",
        "  index = np.where(prediction == top)\n",
        "  prediction = int(index[0] + 1)\n",
        "\n",
        "  annotat['mlp_pred'] =  prediction\n",
        "  pred_anns.append(annotat)\n",
        "\n",
        "  Ypred.append(np.asarray(pred, dtype=np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = [p['mlp_pred'] for p in pred_anns]\n",
        "gt = [p['category_id'] for p in pred_anns]"
      ],
      "metadata": {
        "id": "Rx26Wvb8P_ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "\n",
        "output_file = 'RESULT_FILE.json'\n",
        "\n",
        "with open(output_file, 'w') as file:\n",
        "#  json.dump(pred_anns, file, indent = 4, sort_keys=False)"
      ],
      "metadata": {
        "id": "4W9KuW3VLmRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**weitere verarbeitung für metriken**"
      ],
      "metadata": {
        "id": "7lwLd4jbOwbY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDhw5t_EXwE5"
      },
      "outputs": [],
      "source": [
        "YclassesGt = Ygt \n",
        "YclassesPred = []\n",
        "\n",
        "for elem in Ypred:\n",
        "  top = np.amax(elem)\n",
        "  index = np.where(elem == top)\n",
        "  YclassesPred.append(int(index[0])+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyIVearm_EbO"
      },
      "outputs": [],
      "source": [
        "YclassesGt = [int(Y) for Y in YclassesGt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z62xeAiwG7_s"
      },
      "outputs": [],
      "source": [
        "Ypred = YclassesPred\n",
        "Ygt = YclassesGt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbyUTzD6nnst"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix as confusion\n",
        "\n",
        "matr = confusion(Ygt, Ypred)  #confusionmatrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLDWg9l-r7UF"
      },
      "outputs": [],
      "source": [
        "norm_matrix = np.zeros(matr.shape)\n",
        "for i in range(matr.shape[0]):\n",
        "  for j in range(matr.shape[1]):\n",
        "    norm_matrix[i,j] = matr[i,j]/np.sum(matr[i,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jUwukOsq3Ct"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "#confusionmatrix in schön\n",
        "disp = ConfusionMatrixDisplay(matr)\n",
        "disp.plot()\n",
        "disp1 = ConfusionMatrixDisplay(norm_matrix)\n",
        "disp1.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77FZOH5iBLte"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, precision_score, recall_score\n",
        "\n",
        "#metriken (accuracy, precision, recall)\n",
        "accuracy = accuracy_score(Ygt, Ypred)\n",
        "#avg_prec = average_precision_score(Ygt, Ypred)\n",
        "f1 = f1_score(Ygt, Ypred, average = None)\n",
        "precision = precision_score(Ygt, Ypred, average = None)\n",
        "recall = recall_score(Ygt, Ypred, average = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MzdObuvtKZ1"
      },
      "outputs": [],
      "source": [
        "print(accuracy)\n",
        "print(f1)\n",
        "print(precision)\n",
        "print(recall)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dino_mlp_channelisland.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}